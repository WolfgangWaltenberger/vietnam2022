{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017d93a6",
   "metadata": {},
   "source": [
    "# Exercise #1: logistic regression in two dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb157b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756256ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the 2d data (x_data), with the labels (y_data).\n",
    "## the labels are {0,1}.\n",
    "x_data, y_data = torch.load ( \"01_logit.p\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now define your neural network.\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        ...\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ## the forward pass must consist of a \n",
    "        ## sigmoidal function (F.sigmoid), applied to \n",
    "        ## a linear layer ( torch.nn.Linear ), that takes\n",
    "        ## x as its input.\n",
    "        y_pred =  ...\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37031588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f666a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define your loss function (e.g. torch.nn.BCELoss)\n",
    "criterion = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b128adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## choose an optimizer (torch.optim.Adam, torch.optim.SGD, ... )\n",
    "## it takes model.parameters() as input. Choose a learning rate.\n",
    "optimizer = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95575fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    # Forward pass: Compute predicted y by passing x_data to the model\n",
    "    y_pred = model(x_data)\n",
    "    \n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print ( epoch, loss.data.item() )\n",
    "    \n",
    "    # Reset gradient, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "## print the result\n",
    "for f in model.parameters():\n",
    "    print('data is', f.data, \"gradient is\", f.grad )\n",
    "\n",
    "## obtain the learned weights\n",
    "w = list(model.parameters())\n",
    "w0 = w[0].data.numpy()\n",
    "w1 = w[1].data.numpy()\n",
    "\n",
    "print ( \"Final gradient descent, adam:\", w )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435418f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## plot the data and decision boundary\n",
    "plt.scatter(x_data[:,0], x_data[:,1], c=y_data.reshape(100), s=100, alpha=0.5)\n",
    "x_axis = np.linspace(-6, 6, 100)\n",
    "y_axis = -(w1[0] + x_axis*w0[0][0]) / w0[0][1]\n",
    "line_up, = plt.plot(x_axis, y_axis,'r--', label='decision boundary')\n",
    "plt.legend(handles=[line_up])\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "#plt.show()\n",
    "plt.savefig ( \"01_logit.png\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
